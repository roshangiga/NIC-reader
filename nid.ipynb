{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.033335Z",
     "start_time": "2024-04-24T21:20:52.028311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specify the path to Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'  # Adjust according to your installation path\n"
   ],
   "id": "557f556f1db9c07c",
   "outputs": [],
   "execution_count": 288
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.043567Z",
     "start_time": "2024-04-24T21:20:52.039640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_id_card_details(name, image_path):\n",
    "     # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Assume the largest contour is the ID card (this might need tuning based on your images)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Compute the bounding rectangle for the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Extract the region of interest (ROI) using the coordinates of the rectangle\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Save or display the ROI\n",
    "    cv2.imwrite(name, roi)\n",
    "    cv2.imshow('ID Card', roi)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "e5b2e6e4d24ad214",
   "outputs": [],
   "execution_count": 289
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.051983Z",
     "start_time": "2024-04-24T21:20:52.044571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_image(name, image_path, x, y, width=400, height=33):\n",
    "    # The user wants to split the image into multiple pieces, starting with the first five rows.\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Get the image dimensions\n",
    "    h, w = image.shape\n",
    "    \n",
    "    # Define the starting point, width, and height of the rectangle\n",
    "    start_x = int(w * x)\n",
    "    start_y = int(h * y)\n",
    "    \n",
    "    # Crop the rectangle from the image\n",
    "    cropped_image = image[start_y:start_y+height, start_x:start_x+width]\n",
    "    \n",
    "    # Save or display the cropped image\n",
    "    cv2.imshow(name, cropped_image)\n",
    "    \n",
    "    # Optionally, save the cropped image\n",
    "    path = f\"split/{name}\"\n",
    "    cv2.imwrite(path, cropped_image)\n",
    "    \n",
    "    # Display the cropped image\n",
    "    # plt.imshow(cropped_image)\n",
    "    # plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    # plt.show()\n",
    "    \n",
    "    return path\n",
    "    "
   ],
   "id": "dfc278f01ea60de3",
   "outputs": [],
   "execution_count": 290
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.064759Z",
     "start_time": "2024-04-24T21:20:52.056513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Check the contrast by measuring the standard deviation of pixel intensities\n",
    "    contrast = np.std(image)\n",
    "    \n",
    "    print(\"Contrast: \", contrast)\n",
    "    \n",
    "    # if contrast > 50.0:\n",
    "    #     # Scale down the intensity to reduce the contrast\n",
    "    #     # Assuming the image is in the range [0, 255], reduce the higher values\n",
    "    #     image = np.clip(image * 0.1, 0, 15).astype(np.uint8)\n",
    "    #     # Apply blur to reduce noise and improve edge detection\n",
    "    #     image = cv2.blur(image,(5,5))\n",
    "    # \n",
    "    # else:\n",
    "    #     # Increase the contrast by scaling up the pixel intensities\n",
    "    #     image = np.clip(image * 0.1, 0, 255).astype(np.uint8)\n",
    "    #     # Apply blur to reduce noise and improve edge detection\n",
    "    #     image = cv2.blur(image,(1,1))\n",
    "        \n",
    "    # Apply a mask to exclude the photo and signature if their positions are consistent\n",
    "    h, w = image.shape\n",
    "    mask = np.ones_like(image) * 255\n",
    "\n",
    "    mask[0:int(h*0.89), 0:int(w*0.31)] = 0 # hide photo\n",
    "    mask[:int(h*0.21), :] = 0  # hide header\n",
    "    mask[int(h*0.68):, int(w*0.335):] = 0  # Applying mask to bottom right corner # Exclude signature\n",
    "    \n",
    "    # Apply the mask\n",
    "    image = cv2.bitwise_and(image, mask)\n",
    "\n",
    "        \n",
    "    # Apply thresholding to binarize the image using Otsu's method\n",
    "    _, thresh_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(thresh_image, (795, 500))\n",
    "\n",
    "    # Save the processed image temporarily\n",
    "    temp_processed_path = 'temp_processed_image.png'\n",
    "    cv2.imwrite(temp_processed_path, resized_image)\n",
    "    \n",
    "    return temp_processed_path"
   ],
   "id": "a51ab71a13b22778",
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.093273Z",
     "start_time": "2024-04-24T21:20:52.088390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to perform OCR using Tesseract\n",
    "def perform_ocr(temp_processed_path, cat):\n",
    "    \n",
    "    # Configure Tesseract to only accept alphanumeric characters (whitelist)\n",
    "    if cat == 'gender':\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=MF'\n",
    "    elif cat == 'nid':\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'\n",
    "    else:\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        \n",
    "    # Run Tesseract OCR on the preprocessed image\n",
    "    extracted_text = pytesseract.image_to_string(Image.open(temp_processed_path), config=custom_config)\n",
    "\n",
    "    return extracted_text"
   ],
   "id": "eb656f25471a39c7",
   "outputs": [],
   "execution_count": 292
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.098820Z",
     "start_time": "2024-04-24T21:20:52.095280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#image_path = 'ID Summun Roshan.jpg'\n",
    "image_path = 'mom.png'"
   ],
   "id": "d36748bbce972631",
   "outputs": [],
   "execution_count": 293
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:20:52.808389Z",
     "start_time": "2024-04-24T21:20:52.099824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "surname = split_image('surname.jpg', preprocessed_image, 0.33, 0.21)\n",
    "forename = split_image('forename.jpg', preprocessed_image, 0.33, 0.34)\n",
    "maiden = split_image('maiden.jpg', preprocessed_image, 0.33, 0.48)\n",
    "gender = split_image('gender.jpg', preprocessed_image, 0.33, 0.61, width=30)\n",
    "dob = split_image('dob.jpg', preprocessed_image, 0.45, 0.61, width=200)\n",
    "nid = split_image('nid.jpg', preprocessed_image, 0.02, 0.88, width=250, height=50)\n",
    "\n",
    "# Perform OCR on the preprocessed image\n",
    "print(\"\\nExtracted details:\")\n",
    "print(perform_ocr(surname, cat='surname').strip())\n",
    "print(perform_ocr(forename, cat='forename').strip())\n",
    "print(perform_ocr(maiden, cat='maiden').strip())\n",
    "print(perform_ocr(gender, cat='gender').strip())\n",
    "print(perform_ocr(dob, cat='dob').strip())\n",
    "print(perform_ocr(nid, cat='nid').strip())\n"
   ],
   "id": "64a5b8e6deda21c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast:  46.07811987507643\n",
      "\n",
      "Extracted details:\n",
      "Summun\n",
      "Vedwattee Dabee\n",
      "Ramgoolam\n",
      "F\n",
      "14 Oct 1957\n",
      "R1410570139166\n"
     ]
    }
   ],
   "execution_count": 294
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
