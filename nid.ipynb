{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.749165Z",
     "start_time": "2024-05-01T18:52:50.746655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specify the path to Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'  # Adjust according to your installation path\n"
   ],
   "id": "557f556f1db9c07c",
   "outputs": [],
   "execution_count": 808
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Straighten the Image\n",
    "The first step is to straighten the image if it is rotated. You can use the ORB (Oriented FAST and Rotated BRIEF) algorithm to detect keypoints and match them between the original and a template image. If enough matches are found, you can estimate the homography and rectify the image.\n",
    "\n",
    "Key Points:\n",
    "Feature Detection and Matching: ORB is used here due to its speed and efficiency. You could also consider using SIFT or SURF for potentially better quality at the cost of more computation.\n",
    "Homography Estimation: The homography matrix is estimated based on the point matches found. The RANSAC algorithm helps to find a robust homography.\n",
    "Perspective Warping: The cv2.warpPerspective function applies the computed homography to transform the image to the perspective of the template."
   ],
   "id": "822acbd08db14e71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.774773Z",
     "start_time": "2024-05-01T18:52:50.768691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def straighten_image(image_path, template_path):\n",
    "    # Load the image and template\n",
    "    global rectified_image\n",
    "    original  = cv2.imread(image_path)\n",
    "    template = cv2.imread(template_path)\n",
    "    \n",
    "    if original is None or template is None:\n",
    "        raise FileNotFoundError(\"One or both image paths are incorrect or the images cannot be read.\")\n",
    "\n",
    "    # Check if the original image is larger than the template and resize if necessary\n",
    "    if original.shape[1] > template.shape[1] or original.shape[0] > template.shape[0]:\n",
    "        original = resize_image(original, template.shape[1], template.shape[0])\n",
    "\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    # Find the keypoints and descriptors with ORB\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(original_gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(template_gray, None)\n",
    "    \n",
    "    # Create matcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    # Match descriptors\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    # Sort them in the order of their distance\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    # Draw the top N matches\n",
    "    N = 30  # Number of matches to visualize\n",
    "    matched_image = cv2.drawMatches(original, keypoints1, template, keypoints2, matches[:N], None, flags=2)\n",
    "    \n",
    "    # Assuming enough matches are found, estimate the homography\n",
    "    if len(matches) > 10:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "        # Compute Homography\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        # Use homography\n",
    "        height, width, channels = template.shape\n",
    "        rectified_image = cv2.warpPerspective(original, M, (width, height))\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough matches are found - {}/{}\".format(len(matches), 10))\n",
    "    \n",
    "    # Optionally, display the matches\n",
    "    cv2.imshow('Matches', matched_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if rectified_image is not None:\n",
    "        return rectified_image\n",
    "    else:\n",
    "        return original\n"
   ],
   "id": "e5b2e6e4d24ad214",
   "outputs": [],
   "execution_count": 809
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.802810Z",
     "start_time": "2024-05-01T18:52:50.799874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_image(image, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Resizes the image to the target dimensions using aspect ratio preservation.\n",
    "    :param image: input image array\n",
    "    :param target_width: target width to scale to\n",
    "    :param target_height: target height to scale to\n",
    "    :return: resized image array\n",
    "    \"\"\"\n",
    "    # Calculate the scale factors while preserving the aspect ratio\n",
    "    scale_x = target_width / image.shape[1]\n",
    "    scale_y = target_height / image.shape[0]\n",
    "    scale = min(scale_x, scale_y)\n",
    "\n",
    "    # New dimensions\n",
    "    new_width = int(image.shape[1] * scale)\n",
    "    new_height = int(image.shape[0] * scale)\n",
    "\n",
    "    resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    return resized"
   ],
   "id": "f22ad04fc073869f",
   "outputs": [],
   "execution_count": 810
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Histogram Analysis\n",
    "Glare often results in areas of overexposure, where the pixel values approach the maximum intensity. You can analyze the histogram of the image to check for a spike at the high end of the intensity range, indicating overexposure."
   ],
   "id": "553113dfcaf0ee7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.808116Z",
     "start_time": "2024-05-01T18:52:50.804816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_glare(image, threshold_ratio=0.05):\n",
    "    image = cv2.imread(image)\n",
    "\n",
    "    # Convert to grayscale to simplify the analysis\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0,256])\n",
    "    # Check if there's a significant peak near the maximum intensity\n",
    "    if hist[-1] > threshold_ratio:  # Define 'threshold' based on your specific needs\n",
    "        return True\n",
    "    return False"
   ],
   "id": "6c15c309f99326f8",
   "outputs": [],
   "execution_count": 811
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.827049Z",
     "start_time": "2024-05-01T18:52:50.820798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_image(name, image_path, x, y, width=400, height=38):\n",
    "    # The user wants to split the image into multiple pieces, starting with the first five rows.\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Get the image dimensions\n",
    "    h, w,_ = image.shape\n",
    "    \n",
    "    # Define the starting point, width, and height of the rectangle\n",
    "    start_x = int(w * x)\n",
    "    start_y = int(h * y)\n",
    "    \n",
    "    # Crop the rectangle from the image\n",
    "    cropped_image = image[start_y:start_y+height, start_x:start_x+width]\n",
    "    \n",
    "    # Save or display the cropped image\n",
    "    cv2.imshow(name, cropped_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Optionally, save the cropped image\n",
    "    path = f\"split/{name}\"\n",
    "    cv2.imwrite(path, cropped_image)\n",
    "    \n",
    "    # Display the cropped image\n",
    "    # plt.imshow(cropped_image)\n",
    "    # plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    # plt.show()\n",
    "    \n",
    "    return path\n",
    "    "
   ],
   "id": "dfc278f01ea60de3",
   "outputs": [],
   "execution_count": 812
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.871216Z",
     "start_time": "2024-05-01T18:52:50.866039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    \n",
    "    # Load the image if image_path is a path\n",
    "    # if isinstance(image, str):\n",
    "    #     image = cv2.imread(image)\n",
    "       \n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Check the contrast by measuring the standard deviation of pixel intensities\n",
    "    contrast = np.std(image)\n",
    "    print(\"Contrast: \", contrast)\n",
    "    \n",
    "    # Apply gaussian blur to reduce noise and improve edge detection\n",
    "    image = cv2.blur(image,(1,1))\n",
    "    \n",
    "    # if contrast > 50.0:\n",
    "    #     # Scale down the intensity to reduce the contrast\n",
    "    #     # Assuming the image is in the range [0, 255], reduce the higher values\n",
    "    #     image = np.clip(image * 0.1, 0, 15).astype(np.uint8)\n",
    "    #     # Apply blur to reduce noise and improve edge detection\n",
    "    #     image = cv2.blur(image,(5,5))\n",
    "    # \n",
    "    # else:\n",
    "    #     # Increase the contrast by scaling up the pixel intensities\n",
    "    #     image = np.clip(image * 0.1, 0, 255).astype(np.uint8)\n",
    "    #     # Apply blur to reduce noise and improve edge detection\n",
    "    #     image = cv2.blur(image,(1,1))\n",
    "        \n",
    "    # Apply a mask to exclude the photo and signature if their positions are consistent\n",
    "    h, w = image.shape\n",
    "        \n",
    "    mask = np.ones_like(image) * 255\n",
    "\n",
    "    mask[0:int(h*0.87), 0:int(w*0.31)] = 0 # hide photo\n",
    "    mask[:int(h*0.21), :] = 0  # hide header\n",
    "    mask[int(h*0.68):, int(w*0.335):] = 0  # Applying mask to bottom right corner # Exclude signature\n",
    "    \n",
    "    # Apply the mask\n",
    "    image = cv2.bitwise_and(image, mask)\n",
    "        \n",
    "    # Apply thresholding to binarize the image using Otsu's method\n",
    "    _, thresh_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(thresh_image, (795, 500))\n",
    "\n",
    "    # Save the processed image temporarily\n",
    "    temp_processed_path = 'temp_processed_image.png'\n",
    "    cv2.imwrite(temp_processed_path, resized_image)\n",
    "    \n",
    "    return temp_processed_path"
   ],
   "id": "a51ab71a13b22778",
   "outputs": [],
   "execution_count": 813
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.881318Z",
     "start_time": "2024-05-01T18:52:50.877244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to perform OCR using Tesseract\n",
    "def perform_ocr(temp_processed_path, cat):\n",
    "    \n",
    "    # Configure Tesseract to only accept alphanumeric characters (whitelist)\n",
    "    if cat == 'gender':\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=MF'\n",
    "    elif cat == 'nid':\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'\n",
    "    elif cat == 'dob':\n",
    "        # Whitelist includes necessary uppercase and lowercase letters for months, and digits for the year\n",
    "        custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=\"JFMASONDanebrpyulgpctovc0123456789 \"'\n",
    "    else:\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        \n",
    "    # Run Tesseract OCR on the preprocessed image\n",
    "    extracted_text = pytesseract.image_to_string(Image.open(temp_processed_path), config=custom_config)\n",
    "    \n",
    "    # Specific processing for NID extraction\n",
    "    if cat == 'nid':\n",
    "        # Regex to match NID formats: \"S123456789012D\" or \"S1234567890123\"\n",
    "        nid_pattern = r'\\b[A-Z][0-9]{12}[A-Z]|[A-Z][0-9]{13}\\b'\n",
    "        match = re.search(nid_pattern, extracted_text)\n",
    "        if match:\n",
    "            return match.group(0)  # Return the valid NID\n",
    "        else:\n",
    "            return \"Couldn't read NID\"\n",
    "        \n",
    "    #Specific processing for date extraction\n",
    "    if cat == 'dob':\n",
    "        # Regex to match date format \"DD MMM YYYY\"\n",
    "        date_pattern = r'\\b(0[1-9]|[12][0-9]|3[01]) (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) (19[0-9]{2}|20[0-1][0-9]|202[0-3])\\b'\n",
    "        match = re.search(date_pattern, extracted_text)\n",
    "        if match:\n",
    "            return match.group(0)  # Return the valid date string\n",
    "        else:\n",
    "            return \"No valid date found\"\n",
    "\n",
    "    return extracted_text"
   ],
   "id": "eb656f25471a39c7",
   "outputs": [],
   "execution_count": 814
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:50.888309Z",
     "start_time": "2024-05-01T18:52:50.883328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#image_path = 'ID Summun Roshan.jpg'\n",
    "stright_image_path = 'ID Summun Roshan.jpg'\n",
    "\n",
    "image_path = 'dicksen.jpg'\n",
    "#image_path = 'mom.png'\n",
    "#image_path = 'id_mom_rotated.png'\n",
    "#image_path = 'id_roshan_rotated.png'"
   ],
   "id": "d36748bbce972631",
   "outputs": [],
   "execution_count": 815
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T18:52:59.466256Z",
     "start_time": "2024-05-01T18:52:50.889314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for glare in the image\n",
    "if detect_glare(image_path):\n",
    "    print(\"Glare detected.\")\n",
    "else:\n",
    "    print(\"No glare detected.\")\n",
    "\n",
    "# Straighten the image\n",
    "rectified_image = straighten_image(image_path, stright_image_path)\n",
    "\n",
    "#rectified_image = rectify_image(image_path, stright_image_path)\n",
    "\n",
    "cv2.imshow('Rectified Image', rectified_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(rectified_image)\n",
    "\n",
    "surname = split_image('surname.jpg', preprocessed_image, 0.31, 0.20)\n",
    "forename = split_image('forename.jpg', preprocessed_image, 0.31, 0.33)\n",
    "maiden = split_image('maiden.jpg', preprocessed_image, 0.31, 0.46 )\n",
    "gender = split_image('gender.jpg', preprocessed_image, 0.31, 0.61, width=45)\n",
    "dob = split_image('dob.jpg', preprocessed_image, 0.45, 0.6, width=200, height=50)\n",
    "nid = split_image('nid.jpg', preprocessed_image, 0, 0.88, width=265, height=50)\n",
    "\n",
    "# Perform OCR on the preprocessed image\n",
    "print(\"\\nExtracted details:\")\n",
    "print(perform_ocr(surname, cat='surname').strip())\n",
    "print(perform_ocr(forename, cat='forename').strip())\n",
    "print(perform_ocr(maiden, cat='maiden').strip())\n",
    "print(perform_ocr(gender, cat='gender').strip())\n",
    "print(perform_ocr(dob, cat='dob').strip())\n",
    "print(perform_ocr(nid, cat='nid').strip())\n"
   ],
   "id": "64a5b8e6deda21c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glare detected.\n",
      "Contrast:  43.8805520050961\n",
      "\n",
      "Extracted details:\n",
      "Veloopillay\n",
      "Dicksen\n",
      "\n",
      "M\n",
      "31 Jul 1995\n",
      "No valid NID found\n"
     ]
    }
   ],
   "execution_count": 816
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
